{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields:  ['\"Name\"' '\"Team\"' '\"Position\"' '\"Height\"' '\"Weight\"' '\"Age\"'\n",
      " '\"PosCategory\"']\n",
      "First name:  \"Adam_Donachie\"\n",
      "First name:  \"Adam_Donachie\"  has a weight of 180\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "baseball = genfromtxt('resources/baseball.csv', delimiter=',',\n",
    "                      encoding=\"utf-8\", dtype=None)\n",
    "\n",
    "print(\"Fields: \", baseball[0])\n",
    "print(\"First name: \", baseball[1][0])\n",
    "print(\"First name: \", baseball[1][0], \" has a weight of\", \n",
    "      baseball[1][4])\n",
    "\n",
    "#find out all unique team\n",
    "#find out all unique position\n",
    "#average height by team and position (sorted descending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields:  ['id' ' name' ' rating' ' position' ' height' ' foot' ' rare' ' pace'\n",
      " ' shooting' ' passing' ' dribbling' ' defending' ' heading' ' diving'\n",
      " ' handling' ' kicking' ' reflexes' ' speed' ' positioning']\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "fifa = genfromtxt('resources/fifa.csv', delimiter=',',\n",
    "                      encoding=\"utf-8\", dtype=None)\n",
    "print(\"Fields: \", fifa[0])\n",
    "\n",
    "#we are scouts who want strikers/forward (A) with left foot, with height\n",
    "#more than 190, with shooting over 75.  Basically, he should be able\n",
    "#to both shoot and head!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#3\n",
    "Create a function that compute moving average using a sliding\n",
    "window over a list\n",
    "\n",
    "For example, moving_average([1,2,5,10], n=2)  should produce\n",
    "[1.5 3.5 7.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields:  ['Id' 'SepalLengthCm' 'SepalWidthCm' 'PetalLengthCm' 'PetalWidthCm'\n",
      " 'Species']\n",
      "Rows:  150\n",
      "Rows:  150\n",
      "Unique species:  {'Iris-setosa', 'Iris-virginica', 'Iris-versicolor'}\n",
      "Iris-setosa: 5.006\n",
      "Iris-virginica: 6.587999999999998\n",
      "Iris-versicolor: 5.936\n"
     ]
    }
   ],
   "source": [
    "#4  \n",
    "iris = genfromtxt('resources/iris.csv', delimiter=',',\n",
    "                      encoding=\"utf-8\", dtype=None)\n",
    "\n",
    "iris_without_headers = iris[1:]\n",
    "species = iris_without_headers[:, 5]\n",
    "sepal_length = iris_without_headers[:, 1].astype(float)\n",
    "\n",
    "print(\"Fields: \", iris[0])\n",
    "\n",
    "#calculate how many samples of data we have\n",
    "print(\"Rows: \", len(iris_without_headers)) #minus header  or\n",
    "print(\"Rows: \", np.array(iris_without_headers).shape[0])  #using shape\n",
    "\n",
    "#get all unique species\n",
    "print(\"Unique species: \", set(species))\n",
    "\n",
    "#identify any missing values and replace with mean\n",
    "\n",
    "#compute the mean and std of sepal length of each species\n",
    "for spec in set(species):\n",
    "    cond = species == spec\n",
    "    print(spec, end=\": \")\n",
    "    mean = iris_without_headers[cond][:, 1].astype(float).mean()\n",
    "    print(mean)\n",
    "    \n",
    "#normalize the sepal length such that max value has value 1 and min value has value 0\n",
    "#formula is this x ′ = ( x − x m i n ) / ( x m a x − x m i n )\n",
    "normalized_sepal_length = (sepal_length - np.min(sepal_length))/(np.max(sepal_length) - np.min(sepal_length))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5  combining eeg signals, marker_ts, markers, markers ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields:  ['\"Name\"' '\"Team\"' '\"Position\"' '\"Height\"' '\"Weight\"' '\"Age\"'\n",
      " '\"PosCategory\"']\n",
      "First name:  \"Adam_Donachie\"\n",
      "First name:  \"Adam_Donachie\"  has a weight of 180\n",
      "Teams:  {'\"CLE\"', '\"DET\"', '\"ARZ\"', '\"TEX\"', '\"ATL\"', '\"PHI\"', '\"CHC\"', '\"SEA\"', '\"SD\"', '\"CIN\"', '\"TOR\"', '\"FLA\"', '\"LA\"', '\"WAS\"', '\"STL\"', '\"PIT\"', '\"MLW\"', '\"NYY\"', '\"MIN\"', '\"CWS\"', '\"COL\"', '\"SF\"', '\"NYM\"', '\"BOS\"', '\"ANA\"', '\"OAK\"', '\"HOU\"', '\"KC\"', '\"TB\"', '\"BAL\"'}\n",
      "Number of teams:  30\n",
      "Positions:  {'\"Second_Baseman\"', '\"Third_Baseman\"', '\"Relief_Pitcher\"', '\"First_Baseman\"', '\"Catcher\"', '\"Shortstop\"', '\"Outfielder\"', '\"Starting_Pitcher\"'}\n",
      "Number of positions:  8\n",
      "Average height:  73.6896551724138\n",
      "Sorted height in desc order:  [['74.73181818181818' '\"Third_Baseman\"']\n",
      " ['74.37460317460318' '\"Starting_Pitcher\"']\n",
      " ['74.0' '\"Shortstop\"']\n",
      " ['73.04444444444445' '\"Second_Baseman\"']\n",
      " ['73.01030927835052' '\"Relief_Pitcher\"']\n",
      " ['72.72368421052632' '\"Outfielder\"']\n",
      " ['71.90384615384616' '\"First_Baseman\"']\n",
      " ['71.36206896551724' '\"Catcher\"']]\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "baseball = genfromtxt('resources/baseball.csv', delimiter=',',\n",
    "                      encoding=\"utf-8\", dtype=None)\n",
    "\n",
    "print(\"Fields: \", baseball[0])\n",
    "print(\"First name: \", baseball[1][0])\n",
    "print(\"First name: \", baseball[1][0], \" has a weight of\", \n",
    "      baseball[1][4])\n",
    "\n",
    "baseball_without_header = baseball[1:]\n",
    "\n",
    "#find out all unique team\n",
    "team = baseball_without_header[:, 1]\n",
    "\n",
    "print(\"Teams: \", set(team))\n",
    "print(\"Number of teams: \", len(set(team)))  #you can also do np.unique\n",
    "\n",
    "#find out all unique position\n",
    "pos = baseball_without_header[:, 2]\n",
    "\n",
    "print(\"Positions: \", set(pos))\n",
    "print(\"Number of positions: \", len(set(pos)))\n",
    "\n",
    "#average height by team and position (sorted descending)\n",
    "print(\"Average height: \", baseball_without_header[:, 3].astype(float).mean())\n",
    "\n",
    "height_info = []\n",
    "for each_pos in set(pos):\n",
    "    height = baseball_without_header[pos==each_pos, 3].astype(float).mean()\n",
    "    height_info.append([height, each_pos])\n",
    "\n",
    "#create numpy for easy indexing using np.vstack\n",
    "height_info_numpy = np.vstack(height_info)\n",
    "\n",
    "#use ::-1 for printing in reverse order\n",
    "print(\"Sorted height in desc order: \", np.sort(height_info_numpy, axis=0)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields:  ['id' ' name' ' rating' ' position' ' height' ' foot' ' rare' ' pace'\n",
      " ' shooting' ' passing' ' dribbling' ' defending' ' heading' ' diving'\n",
      " ' handling' ' kicking' ' reflexes' ' speed' ' positioning']\n",
      "Here is our scouted list boss:  [['106019' 'Adriano' '77' 'A' '190' 'Left' '0' '62' '80' '52' '71' '59'\n",
      "  '67' '' '' '' '' '' '']\n",
      " ['138384' 'Marc Janko' '75' 'A' '196' 'Left' '1' '38' '76' '47' '58'\n",
      "  '56' '65' '' '' '' '' '' '']\n",
      " ['178509' 'Olivier Giroud' '76' 'A' '192' 'Left' '1' '63' '77' '64' '67'\n",
      "  '60' '85' '' '' '' '' '' '']\n",
      " ['179752' 'Óscar Cardozo' '81' 'A' '192' 'Left' '1' '42' '85' '71' '73'\n",
      "  '63' '77' '' '' '' '' '' '']\n",
      " ['200647' 'Josip Iličić' '79' 'A' '190' 'Left' '1' '71' '81' '80' '81'\n",
      "  '64' '49' '' '' '' '' '' '']]\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "fifa = genfromtxt('resources/fifa.csv', delimiter=',',\n",
    "                      encoding=\"utf-8\", dtype=None)\n",
    "print(\"Fields: \", fifa[0])\n",
    "\n",
    "#we are scouts who want strikers/forward (A) with left foot, with height\n",
    "#more than 190, with shooting over 75.  Basically, he should be able\n",
    "#to both shoot and head!\n",
    "fifa_without_header = np.array(fifa[1:])\n",
    "\n",
    "#remove some strange trailing whitespace\n",
    "fifa_without_header_cleaned = np.char.lstrip(fifa_without_header)\n",
    "pos = fifa_without_header_cleaned[:, 3]\n",
    "cond_pos = pos == \"A\"\n",
    "\n",
    "filtered_pos = fifa_without_header_cleaned[cond_pos]\n",
    "foot = filtered_pos[:, 5]\n",
    "cond_foot = foot == \"Left\"\n",
    "\n",
    "filtered_pos_foot = filtered_pos[cond_foot]\n",
    "height = filtered_pos_foot[:, 4].astype(float)\n",
    "cond_height = height >= 190\n",
    "\n",
    "filtered_pos_foot_height = filtered_pos_foot[cond_height]\n",
    "shoot = filtered_pos_foot_height[:, 8].astype(float)\n",
    "cond_shoot = shoot > 75\n",
    "\n",
    "filtered_pos_foot_height_shoot = filtered_pos_foot_height[cond_shoot]\n",
    "\n",
    "print(\"Here is our scouted list boss: \", filtered_pos_foot_height_shoot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 3.5 7.5]\n",
      "[1.5 3.5 7.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n [1,   2,   5,  10]\\n [0.5, 0.5]            #(actually need to reverse this, but reverse of it look the same) #without reverse, we call correlation\\n  -->  1*0.5 + 2*0.5 = 1.5\\n  \\n [1,   2,   5,  10]\\n     [0.5, 0.5]            #(actually need to reverse this, but reverse of it look the same) #without reverse, we call correlation\\n  2*0.5 + 5*0.5 = 3.5\\n\\n  [1,   2,   5,  10]\\n           [0.5, 0.5]            #(actually need to reverse this, but reverse of it look the same) #without reverse, we call correlation\\n  5*0.5 + 10*0.5 = 7.5\\n\\nExplanation:\\nThe running mean is a case of the mathematical operation of convolution. \\nFor the running mean, you slide a window along the input and compute the mean of the window's contents. \\nFor discrete 1D signals, convolution is the same thing, except instead of the mean you compute an arbitrary \\nlinear combination, i.e. multiply each element by a corresponding coefficient and add up the results. \\nThose coefficients, one for each position in the window, are sometimes called the convolution kernel. Now, the arithmetic mean of N values is (x_1 + x_2 + ... + x_N) / N, so the corresponding kernel \\nis (1/N, 1/N, ..., 1/N), and that's exactly what we get by using np.ones((N,))/N.\\n\\nConvolution is very very essential in many areas, such as fourier transform for eeg signals or image filtering\\nIn fourier transform, you can think of first vector as composed signal, and second vector\\nis a sinusoidal curve function of a particular frequency, by convoluting them together,\\nyou can get the signal with only that particular frequency.  Think of music, by convoluting\\nit with frequency 1-10Hz, you get only the sound with 1-10hz (just like what you do in a video-editing progrma)\\n\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "\n",
    "data = [1, 2, 5, 10]\n",
    "\n",
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    #we modify [n:] so that it only contains first previous n values accumulation\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    #we ignore n-1 value since they cannot calculate moving average\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "print(moving_average([1,2,5,10], n=2))\n",
    "\n",
    "#we can also use numpy.convolve\n",
    "def moving_average_convolve(data, n=3):\n",
    "    weights = np.ones(n) / n\n",
    "    #mode='valid' make sure our value lies where signal overlap completely\n",
    "    #Basically, mode ‘valid’ returns output of length max(len(weights), len(data)) - min(len(weights), len(data)) + 1\n",
    "    #4-2+1 = 3, thus the resulting list is of length 3\n",
    "    return np.convolve(data, weights, mode='valid')\n",
    "\n",
    "print(moving_average_convolve(data, n=2))\n",
    "\n",
    "#convolve basically do this:\n",
    "'''\n",
    " [1,   2,   5,  10]\n",
    " [0.5, 0.5]            #(actually need to reverse this, but reverse of it look the same) #without reverse, we call correlation\n",
    "  -->  1*0.5 + 2*0.5 = 1.5\n",
    "  \n",
    " [1,   2,   5,  10]\n",
    "     [0.5, 0.5]            #(actually need to reverse this, but reverse of it look the same) #without reverse, we call correlation\n",
    "  2*0.5 + 5*0.5 = 3.5\n",
    "\n",
    "  [1,   2,   5,  10]\n",
    "           [0.5, 0.5]            #(actually need to reverse this, but reverse of it look the same) #without reverse, we call correlation\n",
    "  5*0.5 + 10*0.5 = 7.5\n",
    "\n",
    "Explanation:\n",
    "The running mean is a case of the mathematical operation of convolution. \n",
    "For the running mean, you slide a window along the input and compute the mean of the window's contents. \n",
    "For discrete 1D signals, convolution is the same thing, except instead of the mean you compute an arbitrary \n",
    "linear combination, i.e. multiply each element by a corresponding coefficient and add up the results. \n",
    "Those coefficients, one for each position in the window, are sometimes called the convolution kernel. \\\n",
    "Now, the arithmetic mean of N values is (x_1 + x_2 + ... + x_N) / N, so the corresponding kernel \n",
    "is (1/N, 1/N, ..., 1/N), and that's exactly what we get by using np.ones((N,))/N.\n",
    "\n",
    "Convolution is very very essential in many areas, such as fourier transform for eeg signals or image filtering\n",
    "In fourier transform, you can think of first vector as composed signal, and second vector\n",
    "is a sinusoidal curve function of a particular frequency, by convoluting them together,\n",
    "you can get the signal with only that particular frequency.  Think of music, by convoluting\n",
    "it with frequency 1-10Hz, you get only the sound with 1-10hz (just like what you do in a video-editing progrma)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
