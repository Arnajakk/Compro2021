{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load the MNIST data, and split it into a training set, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for validation, and 10,000 for testing). Then train various classifiers, such as a Random Forest classifier, a Logistic Regression classifier, an SVM, and a MLPClassifier (I haven't taught you yet, but its a simple neural network with multi-layers). \n",
    " \n",
    "Next, try to combine them into an ensemble that outperforms them all on the validation set, using a soft or hard voting classifier. Once you have found one, try it on the test set. How much better does it perform compared to the individual classifiers?\n",
    " \n",
    "Last, attemp to use XGBoost.  Does it improve the accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "\n",
    "#fetching\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "#make sure is int\n",
    "mnist.target = mnist.target.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Load the MNIST data and split it into a training set, a validation set, and \n",
    "#a test set (e.g., use 50,000 instances for training, 10,000 for \n",
    "#validation, and 10,000 for testing)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    mnist.data, mnist.target, test_size=10000, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", probability=True, random_state=42)\n",
    "mlp_clf = MLPClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier\n",
      "Training the LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaklam/DSAI/Environments/teaching_env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVC\n",
      "Training the MLPClassifier\n"
     ]
    }
   ],
   "source": [
    "models = [rnd_clf, log_clf, svm_clf, mlp_clf]\n",
    "for model in models:\n",
    "    print(\"Training the\", model.__class__.__name__)\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9692, 0.9186, 0.9788, 0.9629]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.score(X_val, y_val) for model in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like Logistic Regression is hurting performance.  Not sure whether we should include it on the ensemble but we will think it later....Let's first define a Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaklam/DSAI/Environments/teaching_env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9737"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "named_estimators = [\n",
    "    (\"rnd_clf\", rnd_clf),\n",
    "    (\"log_clf\", log_clf),\n",
    "    (\"svm_clf\", svm_clf),\n",
    "    (\"mlp_clf\", mlp_clf),\n",
    "]\n",
    "\n",
    "voting_clf = VotingClassifier(named_estimators)\n",
    "voting_clf.fit(X_train, y_train)\n",
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9692, 0.9186, 0.9788, 0.9629]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's print out the individual estimator\n",
    "[estimator.score(X_val, y_val) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, we can see that Logistic Regression is hurting the ensemble performance.  We can easily remove using del or fit again.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(random_state=42),\n",
       " SVC(probability=True, random_state=42),\n",
       " MLPClassifier(random_state=42)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del voting_clf.estimators_[1]  #second estimator\n",
    "\n",
    "#print estimators to make sure its deleted\n",
    "voting_clf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9784"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the score again\n",
    "voting_clf.score(X_val, y_val)  #yay increase a little!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, voting classifier is hard voting.  Let's try soft voting.  We can either fit again, but we can also easily set params to soft (this works because soft/hard is simply a function of all the models we already fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.voting = \"soft\"\n",
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm...seems like hard wins....\n",
    "\n",
    "Finally, let's try on our testing set which we should never touch it until the final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting classifier score: 0.9747\n",
      "Each classifier scor: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9645, 0.976, 0.9603]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.voting = \"hard\"\n",
    "print(\"Voting classifier score:\", voting_clf.score(X_test, y_test))\n",
    "print(\"Each classifier scor: \")\n",
    "[estimator.score(X_test, y_test) for estimator in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm...it seems that the voting classifier only slighly increase the accuracy by little, when compared to the best estimator\n",
    "\n",
    "let's try XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.15470\n",
      "Will train until validation_0-merror hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-merror:0.11460\n",
      "[2]\tvalidation_0-merror:0.09720\n",
      "[3]\tvalidation_0-merror:0.08680\n",
      "[4]\tvalidation_0-merror:0.07850\n",
      "[5]\tvalidation_0-merror:0.07580\n",
      "[6]\tvalidation_0-merror:0.07070\n",
      "[7]\tvalidation_0-merror:0.06700\n",
      "[8]\tvalidation_0-merror:0.06270\n",
      "[9]\tvalidation_0-merror:0.05950\n",
      "[10]\tvalidation_0-merror:0.05900\n",
      "[11]\tvalidation_0-merror:0.05450\n",
      "[12]\tvalidation_0-merror:0.05210\n",
      "[13]\tvalidation_0-merror:0.04930\n",
      "[14]\tvalidation_0-merror:0.04810\n",
      "[15]\tvalidation_0-merror:0.04720\n",
      "[16]\tvalidation_0-merror:0.04530\n",
      "[17]\tvalidation_0-merror:0.04360\n",
      "[18]\tvalidation_0-merror:0.04310\n",
      "[19]\tvalidation_0-merror:0.04100\n",
      "[20]\tvalidation_0-merror:0.03910\n",
      "[21]\tvalidation_0-merror:0.03810\n",
      "[22]\tvalidation_0-merror:0.03720\n",
      "[23]\tvalidation_0-merror:0.03650\n",
      "[24]\tvalidation_0-merror:0.03530\n",
      "[25]\tvalidation_0-merror:0.03400\n",
      "[26]\tvalidation_0-merror:0.03430\n",
      "[27]\tvalidation_0-merror:0.03310\n",
      "[28]\tvalidation_0-merror:0.03330\n",
      "[29]\tvalidation_0-merror:0.03310\n",
      "Stopping. Best iteration:\n",
      "[27]\tvalidation_0-merror:0.03310\n",
      "\n",
      "Score:  0.9624\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb_clf = xgboost.XGBClassifier() \n",
    "\n",
    "#not improved after 2 iterations\n",
    "xgb_clf.fit(X_train, y_train,\n",
    "                eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
    "print(\"Score: \", xgb_clf.score(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
