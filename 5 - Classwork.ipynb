{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 \n",
    "#Load boston setting X as boston.data and y as boston.target\n",
    "#Attempt the grid search using polyregression + (linear, ridge, lasso, elastic net), and \n",
    "#Does feature mechanisms on ridge/lasso/elastic helps here?\n",
    "#why do you think the result is like this?\n",
    "#what is the value of alpha, and what does it means?\n",
    "#YOURE CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures()),\n",
      "                ('linearregression', LinearRegression(normalize=True))])\n",
      "Best params:  {'polynomialfeatures__degree': 1}\n",
      "Coefficients:  [ 0.         -1.32750493  0.96447433 -0.17391979  0.19945597 -1.49757922\n",
      "  2.83543215 -0.2962689  -2.80831532  2.76854145 -2.12866545 -2.11368262\n",
      "  1.15569647 -3.29628098]\n",
      "r^2 = 0.677\n",
      "MSE = 30.70\n",
      "adjusted $r^2$ = 0.669\n",
      "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures()),\n",
      "                ('ridge', Ridge(normalize=True))])\n",
      "Best params:  {'polynomialfeatures__degree': 2, 'ridge__alpha': 0.01}\n",
      "Coefficients:  [ 0.00000000e+00 -1.44816043e-01 -5.64496705e-02  3.98000454e-01\n",
      "  4.38845564e-01 -8.51675780e-01  3.55010742e+00 -1.37778256e+00\n",
      " -1.86222774e+00  1.10837142e+00 -1.06506148e+00 -8.12821444e-01\n",
      "  1.25327660e+00 -3.26288191e+00  1.63850840e-01  4.71665252e-01\n",
      " -1.16864891e-01  2.94839213e+00 -6.22042398e-01  3.06562044e-01\n",
      " -4.06958944e-01  3.23915966e-01 -5.05610073e-01  7.88507767e-02\n",
      " -1.76904643e-03 -1.95150526e-01  8.28759419e-01 -1.40279786e-02\n",
      " -1.47291637e-01 -3.77835291e-01 -1.05260793e-01  3.86007665e-01\n",
      " -1.48602296e-01 -2.34990168e-01 -2.56535042e-01  1.64899912e+00\n",
      " -2.39043632e-01 -6.71753413e-04 -8.45489227e-01  7.06366980e-01\n",
      "  1.12873584e-01  1.70190755e+00  1.29119805e+00  3.86520704e-01\n",
      "  1.13346752e+00 -2.66369470e-01 -1.02864736e-01 -7.14654139e-01\n",
      "  5.17037989e-01 -1.47428458e-01  1.29231891e-01 -8.03036850e-02\n",
      " -1.24332017e+00  8.77869262e-01  2.23748681e+00 -2.20870172e-01\n",
      "  2.47809157e-01 -2.10153772e-01  1.93226109e+00 -1.27626004e+00\n",
      " -6.00397306e-01  3.23589368e-01 -1.20613545e+00  1.32846859e+00\n",
      " -4.54569043e-01  1.44167073e-01 -9.66494756e-01 -1.85203224e-01\n",
      "  1.06429619e+00  8.33208580e-02 -7.70178832e-01 -1.65481358e-02\n",
      " -8.65805530e-01 -1.78890282e+00 -6.50107736e-01 -6.66184742e-02\n",
      " -1.11774625e+00  1.77148710e-01  5.78061524e-02  1.99583634e+00\n",
      " -9.63167726e-01 -5.15478757e-02 -1.89452994e+00 -1.13418239e+00\n",
      "  1.41447655e+00 -1.50722171e+00 -1.34879302e+00 -1.89724555e-01\n",
      " -1.17413073e+00  9.58345994e-01 -1.76568237e+00  1.15631771e+00\n",
      "  2.72197448e-01  8.45803956e-02 -2.19448893e+00  6.13619017e-02\n",
      "  2.00723691e+00 -5.79817836e-01 -7.43417754e-01  2.80856528e-02\n",
      "  6.39041805e-01 -1.89029989e-01 -1.69510497e-01 -4.82033755e-01\n",
      "  4.47108430e-01]\n",
      "r^2 = 0.864\n",
      "MSE = 12.89\n",
      "adjusted $r^2$ = 0.861\n",
      "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures()),\n",
      "                ('lasso', Lasso(max_iter=100000, normalize=True, tol=0.01))])\n",
      "Best params:  {'lasso__alpha': 0.001, 'polynomialfeatures__degree': 2}\n",
      "Coefficients:  [ 0.         -0.          0.          0.          0.52669264 -0.54052774\n",
      "  3.63462108 -1.30149492 -2.23959896  0.26774626 -0.77117196 -0.61370178\n",
      "  1.47718532 -3.32703475  0.03052277  0.         -0.48662159  2.22635284\n",
      " -0.37711906  0.24530071 -0.072681    0.         -0.04314569 -0.\n",
      " -0.          0.          0.25777091  0.         -0.         -0.25928257\n",
      " -0.          0.41544237 -0.         -0.03481201 -0.          1.25394545\n",
      " -0.05653989 -0.         -0.67034383  0.4681619   0.          0.88466613\n",
      "  1.18170092  0.01167348  0.         -0.          0.         -0.80572314\n",
      " -0.         -0.          0.03170805 -0.         -1.12073028  0.9183942\n",
      "  1.72743056 -0.07457525 -0.         -0.          1.73962173 -1.19673487\n",
      " -0.39201089  0.         -1.04625309  0.76943708 -0.39751236 -0.\n",
      " -0.3947074  -0.13536371  0.59196459  0.0396723  -0.56610384 -0.\n",
      " -1.08763726 -1.40756927 -0.64712944 -0.04621488 -1.1213758   0.03977968\n",
      "  0.          1.74782509 -0.55361298 -0.         -1.72291162 -0.79782951\n",
      "  1.01987512 -0.640327   -0.64227029 -0.         -0.53961741  0.9263611\n",
      " -1.50350467  1.34332237  0.45864078 -0.         -2.73571165  0.\n",
      "  1.82725147 -0.         -0.         -0.          0.22000628 -0.11571686\n",
      " -0.16019162 -0.44031291  0.54457734]\n",
      "r^2 = 0.859\n",
      "MSE = 13.41\n",
      "adjusted $r^2$ = 0.855\n",
      "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures()),\n",
      "                ('elasticnet',\n",
      "                 ElasticNet(max_iter=100000, normalize=True, tol=0.1))])\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#we know in advance that ElasticNet gonna complain about\n",
    "#needing more iterations.  Unfortunately, to prevent my pc \n",
    "#from crashing, I will simply ignore this warning, and\n",
    "#likely set the tol to a bit high\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning,\n",
    "                        module=\"sklearn\")\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "X = scaler.fit_transform(X)  #by scaling it helps reach convergence faster\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.3, random_state=5)\n",
    "\n",
    "params_linear = {'polynomialfeatures__degree': np.arange(1, 10)}\n",
    "linear = make_pipeline(PolynomialFeatures(), LinearRegression(normalize=True))\n",
    "params_Ridge = {'polynomialfeatures__degree': np.arange(1, 10),\n",
    "                'ridge__alpha': [0.1,0.01,0.001,0.0001]}\n",
    "ridge = make_pipeline(PolynomialFeatures(), Ridge(normalize=True))  \n",
    "params_Lasso = {'polynomialfeatures__degree': np.arange(1, 10),\n",
    "                'lasso__alpha': [1,0.1,0.01,0.001,0.0001]}\n",
    "lasso = make_pipeline(PolynomialFeatures(), \n",
    "                      Lasso(normalize=True, tol=0.01, max_iter=100000))\n",
    "params_Elasticnet = {'polynomialfeatures__degree': np.arange(1, 10),\n",
    "                'elasticnet__alpha': [1,0.1,0.01,0.001,0.0001],\n",
    "                \"elasticnet__l1_ratio\": np.linspace(0, 1, 5)}\n",
    "elastic = make_pipeline(PolynomialFeatures(), \n",
    "                      ElasticNet(normalize=True, tol=0.1, max_iter=100000))\n",
    "\n",
    "params = [params_linear, params_Ridge, params_Lasso, params_Elasticnet]\n",
    "models = [linear, ridge, lasso, elastic]\n",
    "features_name = ['linearregression', 'ridge', 'lasso', 'elasticnet']\n",
    "\n",
    "for ix, model in enumerate(models):\n",
    "    cv = ShuffleSplit(n_splits = 10, test_size = 0.2, random_state=42)\n",
    "    print(model)\n",
    "    grid = GridSearchCV(model, params[ix], cv=cv)\n",
    "    \n",
    "    #grid.fit will fit the model at each grid point\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    #print the best parameters\n",
    "    print(\"Best params: \", grid.best_params_)\n",
    "\n",
    "    #make prediction\n",
    "    model = grid.best_estimator_\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    #print the stats\n",
    "    print(\"Coefficients: \", model.named_steps[features_name[ix]].coef_)\n",
    "    print(f\"r^2 = {r2_score(y_test, y_pred):.3f}\")\n",
    "    print(f\"MSE = {mean_squared_error(y_test, y_pred):.2f}\")\n",
    "    n, p = X.shape[0], X.shape[1]\n",
    "    adjusted_rsqrt = 1-(1-r2_score(y_test, y_pred))*(n-1)/(n-p-1)\n",
    "    print(f\"adjusted $r^2$ = {adjusted_rsqrt:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
